{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#dataset 압축 해제\n",
        "!tar xzf EnglishFnt.tgz -C sample_data/"
      ],
      "metadata": {
        "id": "lYKHqC2TsbkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"protobuf==3.20.3\" tflite-support"
      ],
      "metadata": {
        "id": "dqhy_4UpsfrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. EnglishFnt에서 D/N/E 데이터셋 자동 구축"
      ],
      "metadata": {
        "id": "OhergfcTtXyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "#데이터셋 중 'D', 'N', 'E' 클래스만 추출\n",
        "FNT_BASE = Path(\"sample_data/English/Fnt\")\n",
        "OUT_BASE = Path(\"dataset\")\n",
        "CLASS_MAP = {'Sample014': 'D', 'Sample024': 'N', 'Sample015': 'E'}\n",
        "\n",
        "# dataset/D, dataset/N, dataset/E 폴더 생성 및 초기화\n",
        "for c in ['D', 'N', 'E']:\n",
        "    d = OUT_BASE / c\n",
        "    if d.exists():\n",
        "        shutil.rmtree(d)\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 클래스별로 최대 2000장씩 저장\n",
        "for sample, label in CLASS_MAP.items():\n",
        "    src = FNT_BASE / sample\n",
        "    dst = OUT_BASE / label\n",
        "    files = list(src.glob(\"*.png\"))\n",
        "    random.shuffle(files)\n",
        "    for i, f in enumerate(files[:2000]):\n",
        "        img = Image.open(f).convert(\"L\").resize((32,32)) #32x32 흑백으로 리사이즈\n",
        "        img.save(dst / f\"{label}_{i:04d}.png\")\n",
        "\n",
        "print(\"EnglishFnt → dataset/D,N,E 자동 구축 완료\")"
      ],
      "metadata": {
        "id": "Ul43Ju0Csh4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Keras 데이터셋 로드 및 증강"
      ],
      "metadata": {
        "id": "TsfSW9c-teG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "IMG_SIZE    = (32, 32)\n",
        "BATCH_SIZE  = 64\n",
        "EPOCHS      = 20\n",
        "TFLITE_PATH = \"dne_classifier.tflite\"\n",
        "CLASS_NAMES = [\"D\", \"N\", \"E\"]\n",
        "VALID_SPLIT = 0.2 #검증데이터\n",
        "SEED        = 42\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"dataset\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\", #one-hot encoding\n",
        "    class_names=CLASS_NAMES,\n",
        "    color_mode=\"grayscale\", #흑백\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMG_SIZE,\n",
        "    validation_split=VALID_SPLIT,\n",
        "    subset=\"training\",\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"dataset\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=CLASS_NAMES,\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMG_SIZE,\n",
        "    validation_split=VALID_SPLIT,\n",
        "    subset=\"validation\",\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "normalization = layers.Rescaling(1.0 / 255) #정규화\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomBrightness(0.2), #밝기\n",
        "    layers.RandomContrast(0.2), #대비\n",
        "    layers.RandomRotation(0.1), #회전\n",
        "])\n",
        "\n",
        "def preprocess_train(x, y):\n",
        "    x = tf.expand_dims(x, -1) if x.shape[-1] != 1 else x\n",
        "    x = data_augmentation(x)\n",
        "    x = normalization(x)\n",
        "    return x, y\n",
        "\n",
        "train_ds = train_ds.map(preprocess_train).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds   = val_ds.map(lambda x, y: (normalization(x), y)).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "exq0SQ4BsrFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 셀 크롭 및 리사이즈"
      ],
      "metadata": {
        "id": "uIm6sbN0TXkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tight_crop_and_resize(cell_img, out_size=(32,32), extra_crop=3):\n",
        "    if cell_img is None or cell_img.size == 0:\n",
        "        return np.full(out_size, 255, dtype=np.uint8)\n",
        "    _, threshed = cv2.threshold(cell_img, 200, 255, cv2.THRESH_BINARY)\n",
        "    inv = 255 - threshed\n",
        "    coords = cv2.findNonZero(inv)\n",
        "    if coords is not None:\n",
        "        x, y, w, h = cv2.boundingRect(coords)\n",
        "        # 더 타이트하게 자르기 (상하좌우 extra_crop 만큼 추가로 크롭)\n",
        "        x1 = max(x + extra_crop, 0)\n",
        "        y1 = max(y + extra_crop, 0)\n",
        "        x2 = min(x + w - extra_crop, cell_img.shape[1])\n",
        "        y2 = min(y + h - extra_crop, cell_img.shape[0])\n",
        "        if x2 > x1 and y2 > y1:\n",
        "            cropped = cell_img[y1:y2, x1:x2]\n",
        "        else:\n",
        "            cropped = cell_img[y:y+h, x:x+w]  # 만약 잘못 잘라지면 fallback\n",
        "    else:\n",
        "        cropped = cell_img\n",
        "    resized = cv2.resize(cropped, out_size)\n",
        "    return resized"
      ],
      "metadata": {
        "id": "R3hBuLudTZym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. 셀 분류 함수"
      ],
      "metadata": {
        "id": "VCFmCl06Tdic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_dne(cell_img, interpreter, input_details, output_details, debug=False, r=0, c=0):\n",
        "    tight_img = tight_crop_and_resize(cell_img)\n",
        "    white_ratio = np.mean(tight_img > 180)\n",
        "    if debug:\n",
        "        cv2.imwrite(f'debug_cell_r{r}_c{c}.png', tight_img)\n",
        "    # 1. white_ratio로 빈칸 필터링\n",
        "    if white_ratio > WHITE_THRESH: #기준보다 높으면 '-'로 판단\n",
        "        if debug: print(\"Blank cell detected by white_ratio:\", white_ratio)\n",
        "        return '-'\n",
        "    # 2. 모델 예측\n",
        "    h, w = input_details[0]['shape'][1:3]\n",
        "    inp = tight_img.astype(np.float32) / 255.0\n",
        "    sample = inp.reshape(1, h, w, 1)\n",
        "    interpreter.set_tensor(input_details[0]['index'], sample)\n",
        "    interpreter.invoke()\n",
        "    out = interpreter.get_tensor(output_details[0]['index'])[0]\n",
        "    max_prob = np.max(out)\n",
        "    if debug:\n",
        "        print(f\"Probabilities: D={out[0]:.3f}, N={out[1]:.3f}, E={out[2]:.3f} (max={max_prob:.3f})\")\n",
        "    # 3. max 확률 0.7 미만이면 빈칸으로 처리\n",
        "    if max_prob < 0.7:\n",
        "        if debug: print(\"Blank cell detected by prob:\", max_prob)\n",
        "        return '-'\n",
        "    # 4. 확률이 충분히 높으면 클래스 리턴\n",
        "    return CLASS_LABELS[np.argmax(out)]"
      ],
      "metadata": {
        "id": "L8pZHRLVTepR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. 메인 실행 및 JSON 저장"
      ],
      "metadata": {
        "id": "zkB3vTgKTibd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    img, data_rows, data_cols = get_table_cells(\n",
        "        IMAGE_PATH, header_skip_y=HEADER_SKIP_Y, header_skip_x=HEADER_SKIP_X,\n",
        "        vis_path=\"table_detected.png\"\n",
        "    )\n",
        "\n",
        "    interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL)\n",
        "    interpreter.allocate_tensors()\n",
        "    input_details  = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    result = {}\n",
        "    debug_count = 0\n",
        "    for r, (y1, y2) in enumerate(data_rows):\n",
        "        row_dict = {}\n",
        "        for c, (x1, x2) in enumerate(data_cols):\n",
        "            cell_img = img[y1:y2, x1:x2]\n",
        "            debug = (debug_count < 30)\n",
        "            val = classify_dne(cell_img, interpreter, input_details, output_details,\n",
        "                               debug=debug, r=r, c=c)\n",
        "            row_dict[str(c+1)] = val\n",
        "            if debug: debug_count += 1\n",
        "        result[str(r+1)] = row_dict\n",
        "\n",
        "    with open(\"schedule_inferred.json\", \"w\", encoding=\"utf-8\") as f: #json파일 추출\n",
        "        json.dump(result, f, ensure_ascii=False, indent=2)\n",
        "    print(\"schedule_inferred.json 저장 완료\")\n",
        "    print(json.dumps(result, ensure_ascii=False, indent=2))"
      ],
      "metadata": {
        "id": "IFSZqboKTlST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "JXIbj-v0To8q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}